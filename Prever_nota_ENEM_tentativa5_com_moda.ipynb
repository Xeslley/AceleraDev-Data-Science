{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import linear_model, metrics\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Importar as bases de treino e teste para o desafio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "data= pd.read_csv(\"train.csv\")\n",
    "data2= pd.read_csv(\"test.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* separar a base em targuet e explicativas "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "targuet = data[\"NU_NOTA_MT\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Esta parte foi colocada aqui, pois na hora de executar o modelo na base de teste as colunas não eram as mesmas da base de treino e isso dava erro\n",
    "data = data[data2.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13730, 47)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape\n",
    "#(13730, 47)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4576, 47)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data2.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Vamos escolher e tratas as features da base de treino para criar nosso modelo</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "porcentagem_nulos = pd.DataFrame(data.isnull().sum()/data.shape[0]*100,columns=['porcentagem'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Para tentar melhorar o modelo vamos remover as features com mais de 50% de nulos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TP_ENSINO</th>\n",
       "      <th>TP_DEPENDENCIA_ADM_ESC</th>\n",
       "      <th>Q027</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>porcentagem</th>\n",
       "      <td>68.812819</td>\n",
       "      <td>68.812819</td>\n",
       "      <td>53.699927</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             TP_ENSINO  TP_DEPENDENCIA_ADM_ESC       Q027\n",
       "porcentagem  68.812819               68.812819  53.699927"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "porcentagem_nulos[porcentagem_nulos.porcentagem > 50].T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* baseado no Dicionario_Microdados_Enem_2016 e nas features disponiveis na base de testes vamos listar as features para gerar Dummies depois"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "fazer_dummies = [\n",
    " 'CO_UF_RESIDENCIA',\n",
    " 'SG_UF_RESIDENCIA',\n",
    " 'TP_SEXO',\n",
    " 'TP_COR_RACA',\n",
    " 'TP_NACIONALIDADE',\n",
    " 'TP_ST_CONCLUSAO',\n",
    " 'TP_ANO_CONCLUIU',\n",
    " 'TP_ESCOLA',\n",
    " #'TP_ENSINO', #mais que 50% nulo\n",
    " 'IN_TREINEIRO',\n",
    " #'TP_DEPENDENCIA_ADM_ESC', #mais que 50% nulo\n",
    " 'IN_BAIXA_VISAO',\n",
    " 'IN_CEGUEIRA',\n",
    " 'IN_SURDEZ',\n",
    " 'IN_DISLEXIA',\n",
    " 'IN_DISCALCULIA',\n",
    " 'IN_SABATISTA',\n",
    " 'IN_GESTANTE',\n",
    " 'IN_IDOSO',\n",
    " 'TP_PRESENCA_CN',\n",
    " 'TP_PRESENCA_CH',\n",
    " 'TP_PRESENCA_LC',\n",
    " 'TP_LINGUA',\n",
    " 'TP_STATUS_REDACAO',\n",
    " 'Q001',\n",
    " 'Q002',\n",
    " 'Q006',\n",
    " 'Q024',\n",
    " 'Q025',\n",
    " 'Q026',\n",
    " #'Q027', #mais que 50% nulo\n",
    " 'Q047']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# criar as dimmies e atribuir na base de dados\n",
    "dummies = pd.get_dummies(data[fazer_dummies])\n",
    "data[dummies.columns] = dummies\n",
    "\n",
    "dummies = pd.get_dummies(data2[fazer_dummies])\n",
    "data2[dummies.columns] = dummies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13730, 124)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4576, 124)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data2.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Para fazer a analise, não vamos usar todas as features e temos que retirar as features que deram origem as dummies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \n",
    "colunas_para_remover = ['SG_UF_RESIDENCIA',\n",
    " 'CO_UF_RESIDENCIA',\n",
    " 'NU_INSCRICAO',\n",
    " 'TP_SEXO',\n",
    " 'TP_COR_RACA',\n",
    " 'TP_NACIONALIDADE',\n",
    " 'TP_ST_CONCLUSAO',\n",
    " 'TP_ANO_CONCLUIU',\n",
    " 'TP_ESCOLA',\n",
    " 'TP_ENSINO',\n",
    " 'IN_TREINEIRO',\n",
    " 'TP_DEPENDENCIA_ADM_ESC',\n",
    " 'IN_BAIXA_VISAO',\n",
    " 'IN_CEGUEIRA',\n",
    " 'IN_SURDEZ',\n",
    " 'IN_DISLEXIA',\n",
    " 'IN_DISCALCULIA',\n",
    " 'IN_SABATISTA',\n",
    " 'IN_GESTANTE',\n",
    " 'IN_IDOSO',\n",
    " 'TP_PRESENCA_CN',\n",
    " 'TP_PRESENCA_CH',\n",
    " 'TP_PRESENCA_LC',\n",
    " 'CO_PROVA_CN',\n",
    " 'CO_PROVA_CH',\n",
    " 'CO_PROVA_LC',\n",
    " 'CO_PROVA_MT',\n",
    " 'TP_LINGUA',\n",
    " 'TP_STATUS_REDACAO',\n",
    " 'Q001',\n",
    " 'Q002',\n",
    " 'Q006',\n",
    " 'Q024',\n",
    " 'Q025',\n",
    " 'Q026',\n",
    " 'Q027',\n",
    " 'Q047']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "explanatory_features = list(data.columns)\n",
    "for i in colunas_para_remover:\n",
    "    explanatory_features.remove(i)\n",
    "explanatory_features = data[explanatory_features]\n",
    "#(13730, 78)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13730, 87)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "explanatory_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NU_IDADE           int64\n",
       "NU_NOTA_CN       float64\n",
       "NU_NOTA_CH       float64\n",
       "NU_NOTA_LC       float64\n",
       "NU_NOTA_COMP1    float64\n",
       "                  ...   \n",
       "Q047_A             uint8\n",
       "Q047_B             uint8\n",
       "Q047_C             uint8\n",
       "Q047_D             uint8\n",
       "Q047_E             uint8\n",
       "Length: 87, dtype: object"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "explanatory_features.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* para melhorar o modelo vamos converter as notas de float para int e assumir que os nulos são nota zero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\1570 LITE\\AppData\\Roaming\\Python\\Python36\\site-packages\\pandas\\core\\frame.py:3509: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self[k1] = value[k2]\n"
     ]
    }
   ],
   "source": [
    "teste = pd.DataFrame()\n",
    "for i in explanatory_features.columns:\n",
    "    if explanatory_features[i].dtype == 'float':\n",
    "        teste[i]=(explanatory_features[i].fillna(explanatory_features[i].mode().mean())*100).astype(int)\n",
    "teste.describe()\n",
    "explanatory_features[teste.columns] = teste[teste.columns] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['NU_IDADE',\n",
       " 'NU_NOTA_CN',\n",
       " 'NU_NOTA_CH',\n",
       " 'NU_NOTA_LC',\n",
       " 'NU_NOTA_COMP1',\n",
       " 'NU_NOTA_COMP2',\n",
       " 'NU_NOTA_COMP3',\n",
       " 'NU_NOTA_COMP4',\n",
       " 'NU_NOTA_COMP5',\n",
       " 'NU_NOTA_REDACAO',\n",
       " 'SG_UF_RESIDENCIA_AC',\n",
       " 'SG_UF_RESIDENCIA_AL',\n",
       " 'SG_UF_RESIDENCIA_AM',\n",
       " 'SG_UF_RESIDENCIA_AP',\n",
       " 'SG_UF_RESIDENCIA_BA',\n",
       " 'SG_UF_RESIDENCIA_CE',\n",
       " 'SG_UF_RESIDENCIA_DF',\n",
       " 'SG_UF_RESIDENCIA_ES',\n",
       " 'SG_UF_RESIDENCIA_GO',\n",
       " 'SG_UF_RESIDENCIA_MA',\n",
       " 'SG_UF_RESIDENCIA_MG',\n",
       " 'SG_UF_RESIDENCIA_MS',\n",
       " 'SG_UF_RESIDENCIA_MT',\n",
       " 'SG_UF_RESIDENCIA_PA',\n",
       " 'SG_UF_RESIDENCIA_PB',\n",
       " 'SG_UF_RESIDENCIA_PE',\n",
       " 'SG_UF_RESIDENCIA_PI',\n",
       " 'SG_UF_RESIDENCIA_PR',\n",
       " 'SG_UF_RESIDENCIA_RJ',\n",
       " 'SG_UF_RESIDENCIA_RN',\n",
       " 'SG_UF_RESIDENCIA_RO',\n",
       " 'SG_UF_RESIDENCIA_RR',\n",
       " 'SG_UF_RESIDENCIA_RS',\n",
       " 'SG_UF_RESIDENCIA_SC',\n",
       " 'SG_UF_RESIDENCIA_SE',\n",
       " 'SG_UF_RESIDENCIA_SP',\n",
       " 'SG_UF_RESIDENCIA_TO',\n",
       " 'TP_SEXO_F',\n",
       " 'TP_SEXO_M',\n",
       " 'Q001_A',\n",
       " 'Q001_B',\n",
       " 'Q001_C',\n",
       " 'Q001_D',\n",
       " 'Q001_E',\n",
       " 'Q001_F',\n",
       " 'Q001_G',\n",
       " 'Q001_H',\n",
       " 'Q002_A',\n",
       " 'Q002_B',\n",
       " 'Q002_C',\n",
       " 'Q002_D',\n",
       " 'Q002_E',\n",
       " 'Q002_F',\n",
       " 'Q002_G',\n",
       " 'Q002_H',\n",
       " 'Q006_A',\n",
       " 'Q006_B',\n",
       " 'Q006_C',\n",
       " 'Q006_D',\n",
       " 'Q006_E',\n",
       " 'Q006_F',\n",
       " 'Q006_G',\n",
       " 'Q006_H',\n",
       " 'Q006_I',\n",
       " 'Q006_J',\n",
       " 'Q006_K',\n",
       " 'Q006_L',\n",
       " 'Q006_M',\n",
       " 'Q006_N',\n",
       " 'Q006_O',\n",
       " 'Q006_P',\n",
       " 'Q006_Q',\n",
       " 'Q024_A',\n",
       " 'Q024_B',\n",
       " 'Q024_C',\n",
       " 'Q024_D',\n",
       " 'Q024_E',\n",
       " 'Q025_A',\n",
       " 'Q025_B',\n",
       " 'Q026_A',\n",
       " 'Q026_B',\n",
       " 'Q026_C',\n",
       " 'Q047_A',\n",
       " 'Q047_B',\n",
       " 'Q047_C',\n",
       " 'Q047_D',\n",
       " 'Q047_E']"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(explanatory_features.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* para melhorar o modelo vamos converter as notas de float para int e assumir que os nulos são nota zero e vamos salvar em uma variavel diferente para não modificar a targuet original, para não perder os valores apos a virgula, vamos multiplicar por 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "alvo = (targuet.fillna(targuet.mode().mean())*100).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        39940\n",
       "1        45980\n",
       "2        44530\n",
       "3        44530\n",
       "4        44530\n",
       "         ...  \n",
       "13725    40320\n",
       "13726    45240\n",
       "13727    39800\n",
       "13728    38660\n",
       "13729    42890\n",
       "Name: NU_NOTA_MT, Length: 13730, dtype: int32"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alvo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Dividir a base em treino e teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(explanatory_features, alvo, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Vamos rodar o modelo normalizando e não normalizando o modelo</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=4, normalize=True)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create linear regression object\n",
    "regr2 = linear_model.LinearRegression(normalize=True,n_jobs=4)\n",
    "\n",
    "# Train the model using the training sets\n",
    "regr2.fit(x_train, y_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Apos treinar o modelo, vamos voltar as notas para a ordem de grandeza corretas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test=y_test/100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Vamos fazer as predições usando os modelos treinados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "#normalizado\n",
    "y_test_pred2 = regr2.predict(x_test)\n",
    "y_test_pred2 = y_test_pred2/100\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "31.68"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_pred2.min()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* como as notas não podem ser negativas, então vamos substituir por zero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "#norm_zera_neg\n",
    "y_test_pred2_1 = y_test_pred2.copy()\n",
    "y_test_pred2_1[y_test_pred2_1<0] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* outra opção é converter para positivo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "#norm_abs\n",
    "y_test_pred2_2 = y_test_pred2.copy()\n",
    "y_test_pred2_2[y_test_pred2_2<0] = y_test_pred2_2[y_test_pred2_2<0]*-1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Vamos ver as metricas das tentativas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "metricas= pd.DataFrame(columns=['Mean Absolute Error:','Mean Squared Error:','Root Mean Squared Error:'],\n",
    "index=['normalizado','norm_zera_neg','norm_abs'],\n",
    "data=[\n",
    "[metrics.mean_absolute_error(y_test, y_test_pred2),metrics.mean_squared_error(y_test, y_test_pred2),np.sqrt(metrics.mean_squared_error(y_test, y_test_pred2))],\n",
    "[metrics.mean_absolute_error(y_test, y_test_pred2_1),metrics.mean_squared_error(y_test, y_test_pred2_1),np.sqrt(metrics.mean_squared_error(y_test, y_test_pred2_1))],\n",
    "[metrics.mean_absolute_error(y_test, y_test_pred2_2),metrics.mean_squared_error(y_test, y_test_pred2_2),np.sqrt(metrics.mean_squared_error(y_test, y_test_pred2_2))]])\n",
    "\n",
    "# nao_normalizado\t50.164493\t4743.872600\t68.875777\n",
    "# normalizado\t50.165393\t4743.980423\t68.876559\n",
    "# nao_norm_zera_neg\t48.371068\t4718.357238\t68.690299\n",
    "# norm_zera_neg\t48.368426\t4718.419648\t68.690754\n",
    "# nao_norm_abs\t50.164493\t4743.872600\t68.875777\n",
    "# norm_abs\t50.165393\t4743.980423\t68.876559\n",
    "# nao_norm_abs_max_lim\t48.371068\t4718.357238\t68.690299\n",
    "# norm_abs_max_lim\t48.368426\t4718.419648\t68.690754"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Mean Absolute Error:</th>\n",
       "      <th>Mean Squared Error:</th>\n",
       "      <th>Root Mean Squared Error:</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>normalizado</th>\n",
       "      <td>46.83424</td>\n",
       "      <td>4232.335007</td>\n",
       "      <td>65.056399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>norm_zera_neg</th>\n",
       "      <td>46.83424</td>\n",
       "      <td>4232.335007</td>\n",
       "      <td>65.056399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>norm_abs</th>\n",
       "      <td>46.83424</td>\n",
       "      <td>4232.335007</td>\n",
       "      <td>65.056399</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Mean Absolute Error:  Mean Squared Error:  \\\n",
       "normalizado                46.83424          4232.335007   \n",
       "norm_zera_neg              46.83424          4232.335007   \n",
       "norm_abs                   46.83424          4232.335007   \n",
       "\n",
       "               Root Mean Squared Error:  \n",
       "normalizado                   65.056399  \n",
       "norm_zera_neg                 65.056399  \n",
       "norm_abs                      65.056399  "
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metricas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* O melhor modelo foi o modelo em que substituimos as predições negativas por zero"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Vamos aplicar o modelo na base de testes</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Vamos selecionar as features da mesma forma ue foi feita na base de treino"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4576, 87)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "explanatory_features = list(data2.columns)\n",
    "for i in colunas_para_remover:\n",
    "    explanatory_features.remove(i)\n",
    "explanatory_features = data2[explanatory_features]\n",
    "explanatory_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\1570 LITE\\AppData\\Roaming\\Python\\Python36\\site-packages\\pandas\\core\\frame.py:3509: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self[k1] = value[k2]\n"
     ]
    }
   ],
   "source": [
    "teste = pd.DataFrame()\n",
    "for i in explanatory_features.columns:\n",
    "    if explanatory_features[i].dtype == 'float':\n",
    "        teste[i]=(explanatory_features[i].fillna(explanatory_features[i].mode().mean())*100).astype(int)\n",
    "teste.describe()\n",
    "explanatory_features[teste.columns] = teste[teste.columns] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Vamos criar o Data Frame de resposta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "answer = pd.DataFrame()\n",
    "answer['NU_INSCRICAO'] = data2['NU_INSCRICAO']\n",
    "answer['NU_NOTA_MT']= regr2.predict(explanatory_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "#norm_zera_neg\n",
    "y_test_pred2_1 = answer['NU_NOTA_MT'].copy()\n",
    "y_test_pred2_1[y_test_pred2_1<0] = 0\n",
    "answer['NU_NOTA_MT'] = y_test_pred2_1/100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Vamos salvar as respostas como 'answer.csv'</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "answer.to_csv('answer.csv',index=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
