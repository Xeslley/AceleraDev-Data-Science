{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import linear_model, metrics\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Importar as bases de treino e teste para o desafio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "data= pd.read_csv(\"train.csv\")\n",
    "data2= pd.read_csv(\"test.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* separar a base em targuet e explicativas "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "targuet = data[\"NU_NOTA_MT\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Esta parte foi colocada aqui, pois na hora de executar o modelo na base de teste as colunas não eram as mesmas da base de treino e isso dava erro\n",
    "data = data[data2.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13730, 47)"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape\n",
    "#(13730, 47)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4576, 47)"
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data2.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Vamos escolher e tratas as features da base de treino para criar nosso modelo</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "porcentagem_nulos = pd.DataFrame(data.isnull().sum()/data.shape[0]*100,columns=['porcentagem'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Para tentar melhorar o modelo vamos remover as features com mais de 50% de nulos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TP_ENSINO</th>\n",
       "      <th>TP_DEPENDENCIA_ADM_ESC</th>\n",
       "      <th>Q027</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>porcentagem</th>\n",
       "      <td>68.812819</td>\n",
       "      <td>68.812819</td>\n",
       "      <td>53.699927</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             TP_ENSINO  TP_DEPENDENCIA_ADM_ESC       Q027\n",
       "porcentagem  68.812819               68.812819  53.699927"
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "porcentagem_nulos[porcentagem_nulos.porcentagem > 50].T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* baseado no Dicionario_Microdados_Enem_2016 e nas features disponiveis na base de testes vamos listar as features para gerar Dummies depois"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "fazer_dummies = [\n",
    " 'CO_UF_RESIDENCIA',\n",
    " 'SG_UF_RESIDENCIA',\n",
    " 'TP_SEXO',\n",
    " 'TP_COR_RACA',\n",
    " 'TP_NACIONALIDADE',\n",
    " 'TP_ST_CONCLUSAO',\n",
    " 'TP_ANO_CONCLUIU',\n",
    " 'TP_ESCOLA',\n",
    " #'TP_ENSINO', #mais que 50% nulo\n",
    " 'IN_TREINEIRO',\n",
    " #'TP_DEPENDENCIA_ADM_ESC', #mais que 50% nulo\n",
    " 'IN_BAIXA_VISAO',\n",
    " 'IN_CEGUEIRA',\n",
    " 'IN_SURDEZ',\n",
    " 'IN_DISLEXIA',\n",
    " 'IN_DISCALCULIA',\n",
    " 'IN_SABATISTA',\n",
    " 'IN_GESTANTE',\n",
    " 'IN_IDOSO',\n",
    " 'TP_PRESENCA_CN',\n",
    " 'TP_PRESENCA_CH',\n",
    " 'TP_PRESENCA_LC',\n",
    " 'TP_LINGUA',\n",
    " 'TP_STATUS_REDACAO',\n",
    " 'Q001',\n",
    " 'Q002',\n",
    " 'Q006',\n",
    " 'Q024',\n",
    " 'Q025',\n",
    " 'Q026',\n",
    " #'Q027', #mais que 50% nulo\n",
    " 'Q047']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "# criar as dimmies e atribuir na base de dados\n",
    "dummies = pd.get_dummies(data[fazer_dummies])\n",
    "data[dummies.columns] = dummies\n",
    "\n",
    "dummies = pd.get_dummies(data2[fazer_dummies])\n",
    "data2[dummies.columns] = dummies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13730, 124)"
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4576, 124)"
      ]
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data2.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Para fazer a analise, não vamos usar todas as features e temos que retirar as features que deram origem as dummies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \n",
    "colunas_para_remover = ['SG_UF_RESIDENCIA',\n",
    " 'CO_UF_RESIDENCIA',\n",
    " 'NU_INSCRICAO',\n",
    " 'TP_SEXO',\n",
    " 'TP_COR_RACA',\n",
    " 'TP_NACIONALIDADE',\n",
    " 'TP_ST_CONCLUSAO',\n",
    " 'TP_ANO_CONCLUIU',\n",
    " 'TP_ESCOLA',\n",
    " 'TP_ENSINO',\n",
    " 'IN_TREINEIRO',\n",
    " 'TP_DEPENDENCIA_ADM_ESC',\n",
    " 'IN_BAIXA_VISAO',\n",
    " 'IN_CEGUEIRA',\n",
    " 'IN_SURDEZ',\n",
    " 'IN_DISLEXIA',\n",
    " 'IN_DISCALCULIA',\n",
    " 'IN_SABATISTA',\n",
    " 'IN_GESTANTE',\n",
    " 'IN_IDOSO',\n",
    " 'TP_PRESENCA_CN',\n",
    " 'TP_PRESENCA_CH',\n",
    " 'TP_PRESENCA_LC',\n",
    " 'CO_PROVA_CN',\n",
    " 'CO_PROVA_CH',\n",
    " 'CO_PROVA_LC',\n",
    " 'CO_PROVA_MT',\n",
    " 'TP_LINGUA',\n",
    " 'TP_STATUS_REDACAO',\n",
    " 'Q001',\n",
    " 'Q002',\n",
    " 'Q006',\n",
    " 'Q024',\n",
    " 'Q025',\n",
    " 'Q026',\n",
    " 'Q027',\n",
    " 'Q047']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "explanatory_features = list(data.columns)\n",
    "for i in colunas_para_remover:\n",
    "    explanatory_features.remove(i)\n",
    "explanatory_features = data[explanatory_features]\n",
    "#(13730, 78)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13730, 87)"
      ]
     },
     "execution_count": 227,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "explanatory_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NU_IDADE           int64\n",
       "NU_NOTA_CN       float64\n",
       "NU_NOTA_CH       float64\n",
       "NU_NOTA_LC       float64\n",
       "NU_NOTA_COMP1    float64\n",
       "                  ...   \n",
       "Q047_A             uint8\n",
       "Q047_B             uint8\n",
       "Q047_C             uint8\n",
       "Q047_D             uint8\n",
       "Q047_E             uint8\n",
       "Length: 87, dtype: object"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "explanatory_features.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* para melhorar o modelo vamos converter as notas de float para int e assumir que os nulos são nota zero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "teste = pd.DataFrame()\n",
    "for i in explanatory_features.columns:\n",
    "    if explanatory_features[i].dtype == 'float':\n",
    "        teste[i]=(explanatory_features[i].fillna(0)*100).astype(int)\n",
    "teste.describe()\n",
    "explanatory_features[teste.columns] = teste[teste.columns] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NU_NOTA_CN         int32\n",
       "NU_NOTA_CH         int32\n",
       "NU_NOTA_LC         int32\n",
       "NU_NOTA_COMP1      int32\n",
       "NU_NOTA_COMP2      int32\n",
       "NU_NOTA_COMP3      int32\n",
       "NU_NOTA_COMP4      int32\n",
       "NU_NOTA_COMP5      int32\n",
       "NU_NOTA_REDACAO    int32\n",
       "dtype: object"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#verificar se estão nos tipos corretos\n",
    "teste.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* para melhorar o modelo vamos converter as notas de float para int e assumir que os nulos são nota zero e vamos salvar em uma variavel diferente para não modificar a targuet original, para não perder os valores apos a virgula, vamos multiplicar por 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "alvo = (targuet.fillna(0)*100).astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Dividir a base em treino e teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(explanatory_features, alvo, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Vamos rodar o modelo normalizando e não normalizando o modelo</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=4, normalize=True)"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create linear regression object\n",
    "regr = linear_model.LinearRegression(normalize=False,n_jobs=4)\n",
    "\n",
    "# Train the model using the training sets\n",
    "regr.fit(x_train, y_train)\n",
    "\n",
    "# Create linear regression object\n",
    "regr2 = linear_model.LinearRegression(normalize=True,n_jobs=4)\n",
    "\n",
    "# Train the model using the training sets\n",
    "regr2.fit(x_train, y_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Apos treinar o modelo, vamos voltar as notas para a ordem de grandeza corretas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test=y_test/100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Vamos fazer as predições usando os modelos treinados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions using the testing set\n",
    "#nao_normalizado\n",
    "y_test_pred = regr.predict(x_test)\n",
    "y_test_pred = y_test_pred/100\n",
    "\n",
    "#normalizado\n",
    "y_test_pred2 = regr2.predict(x_test)\n",
    "y_test_pred2 = y_test_pred2/100\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-25.6"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_pred2.min()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* como as notas não podem ser negativas, então vamos substituir por zero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "#nao_norm_zera_neg\n",
    "y_test_pred_1 = y_test_pred.copy()\n",
    "y_test_pred_1[y_test_pred_1<0] = 0\n",
    "\n",
    "#norm_zera_neg\n",
    "y_test_pred2_1 = y_test_pred2.copy()\n",
    "y_test_pred2_1[y_test_pred2_1<0] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* outra opção é converter para positivo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "#nao_norm_abs\n",
    "y_test_pred_2 = y_test_pred.copy()\n",
    "y_test_pred_2[y_test_pred_2<0] = y_test_pred_2[y_test_pred_2<0]*-1\n",
    "\n",
    "#norm_abs\n",
    "y_test_pred2_2 = y_test_pred2.copy()\n",
    "y_test_pred2_2[y_test_pred2_2<0] = y_test_pred2_2[y_test_pred2_2<0]*-1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Vamos ver as metricas das tentativas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "metricas= pd.DataFrame(columns=['Mean Absolute Error:','Mean Squared Error:','Root Mean Squared Error:'],\n",
    "index=['nao_normalizado','normalizado','nao_norm_zera_neg','norm_zera_neg','nao_norm_abs','norm_abs'],\n",
    "data=[\n",
    "[metrics.mean_absolute_error(y_test, y_test_pred),metrics.mean_squared_error(y_test, y_test_pred),np.sqrt(metrics.mean_squared_error(y_test, y_test_pred))],\n",
    "[metrics.mean_absolute_error(y_test, y_test_pred2),metrics.mean_squared_error(y_test, y_test_pred2),np.sqrt(metrics.mean_squared_error(y_test, y_test_pred2))],\n",
    "[metrics.mean_absolute_error(y_test, y_test_pred_1),metrics.mean_squared_error(y_test, y_test_pred_1),np.sqrt(metrics.mean_squared_error(y_test, y_test_pred_1))],\n",
    "[metrics.mean_absolute_error(y_test, y_test_pred2_1),metrics.mean_squared_error(y_test, y_test_pred2_1),np.sqrt(metrics.mean_squared_error(y_test, y_test_pred2_1))],\n",
    "[metrics.mean_absolute_error(y_test, y_test_pred_2),metrics.mean_squared_error(y_test, y_test_pred_2),np.sqrt(metrics.mean_squared_error(y_test, y_test_pred_2))],\n",
    "[metrics.mean_absolute_error(y_test, y_test_pred2_2),metrics.mean_squared_error(y_test, y_test_pred2_2),np.sqrt(metrics.mean_squared_error(y_test, y_test_pred2_2))]])\n",
    "\n",
    "# nao_normalizado\t50.164493\t4743.872600\t68.875777\n",
    "# normalizado\t50.165393\t4743.980423\t68.876559\n",
    "# nao_norm_zera_neg\t48.371068\t4718.357238\t68.690299\n",
    "# norm_zera_neg\t48.368426\t4718.419648\t68.690754\n",
    "# nao_norm_abs\t50.164493\t4743.872600\t68.875777\n",
    "# norm_abs\t50.165393\t4743.980423\t68.876559\n",
    "# nao_norm_abs_max_lim\t48.371068\t4718.357238\t68.690299\n",
    "# norm_abs_max_lim\t48.368426\t4718.419648\t68.690754"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Mean Absolute Error:</th>\n",
       "      <th>Mean Squared Error:</th>\n",
       "      <th>Root Mean Squared Error:</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>nao_normalizado</th>\n",
       "      <td>50.158176</td>\n",
       "      <td>4743.828278</td>\n",
       "      <td>68.875455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>normalizado</th>\n",
       "      <td>49.877515</td>\n",
       "      <td>4746.363388</td>\n",
       "      <td>68.893856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nao_norm_zera_neg</th>\n",
       "      <td>48.388063</td>\n",
       "      <td>4718.893157</td>\n",
       "      <td>68.694200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>norm_zera_neg</th>\n",
       "      <td>48.500759</td>\n",
       "      <td>4729.625926</td>\n",
       "      <td>68.772276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nao_norm_abs</th>\n",
       "      <td>50.158176</td>\n",
       "      <td>4743.828278</td>\n",
       "      <td>68.875455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>norm_abs</th>\n",
       "      <td>49.877515</td>\n",
       "      <td>4746.363388</td>\n",
       "      <td>68.893856</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Mean Absolute Error:  Mean Squared Error:  \\\n",
       "nao_normalizado               50.158176          4743.828278   \n",
       "normalizado                   49.877515          4746.363388   \n",
       "nao_norm_zera_neg             48.388063          4718.893157   \n",
       "norm_zera_neg                 48.500759          4729.625926   \n",
       "nao_norm_abs                  50.158176          4743.828278   \n",
       "norm_abs                      49.877515          4746.363388   \n",
       "\n",
       "                   Root Mean Squared Error:  \n",
       "nao_normalizado                   68.875455  \n",
       "normalizado                       68.893856  \n",
       "nao_norm_zera_neg                 68.694200  \n",
       "norm_zera_neg                     68.772276  \n",
       "nao_norm_abs                      68.875455  \n",
       "norm_abs                          68.893856  "
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metricas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* O melhor modelo foi o modelo em que substituimos as predições negativas por zero"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Vamos aplicar o modelo na base de testes</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Vamos selecionar as features da mesma forma ue foi feita na base de treino"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4576, 87)"
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "explanatory_features = list(data2.columns)\n",
    "for i in colunas_para_remover:\n",
    "    explanatory_features.remove(i)\n",
    "explanatory_features = data2[explanatory_features]\n",
    "explanatory_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "teste = pd.DataFrame()\n",
    "for i in explanatory_features.columns:\n",
    "    if explanatory_features[i].dtype == 'float':\n",
    "        teste[i]=(explanatory_features[i].fillna(0)*100).astype(int)\n",
    "teste.describe()\n",
    "explanatory_features[teste.columns] = teste[teste.columns] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Vamos criar o Data Frame de resposta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "answer = pd.DataFrame()\n",
    "answer['NU_INSCRICAO'] = data2['NU_INSCRICAO']\n",
    "answer['NU_NOTA_MT']= regr2.predict(explanatory_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "#norm_zera_neg\n",
    "y_test_pred2_1 = answer['NU_NOTA_MT'].copy()\n",
    "y_test_pred2_1[y_test_pred2_1<0] = 0\n",
    "answer['NU_NOTA_MT'] = y_test_pred2_1/100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Vamos salvar as respostas como 'answer.csv'</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "answer.to_csv('answer.csv',index=0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
